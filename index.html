<!doctype html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-L7QH2NS5H0"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-L7QH2NS5H0');
  </script>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="xDNWUvx6Q5EWK5YYSyKvK8DZTmvXhKsGX203Ll-BFFE">
  <title>Sebastian Koch</title>

  <!-- Favicon -->
  <link rel="icon" type="image/png" href="media/icon.png">

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic&display=swap" rel="stylesheet">

  <style>

    /* ===========================
       Base theme + typography
       =========================== */
    :root {
      color-scheme: light dark;

      --bg: #ffffff;
      --fg: #111827;
      --muted: #374151;

      --card: #ffffff;
      --border: #e5e7eb;

      --link: #1772d0;
      --link-visited: var(--link);
      --link-hover: #f09228;

      --shadow: 0 1px 0 rgba(17, 24, 39, 0.04), 0 8px 24px rgba(17, 24, 39, 0.08);
      --radius: 14px;

      --font: 'Roboto', system-ui, -apple-system, Segoe UI, sans-serif;
    }

    /* Dark mode variables */
    body.dark {
      /* VS Code Dark+ inspired palette */
      --bg: #1e1e1e;
      --fg: #d4d4d4;
      --muted: #9da3a6;

      --card: #252526;
      --border: #3c3c3c;

      --link: #3794ff;
      --link-visited: var(--link);
      --link-hover: #4fc1ff;

      --shadow: 0 1px 0 rgba(0,0,0,0.35), 0 10px 24px rgba(0,0,0,0.40);
    }

    html, body {
      margin: 0;
      padding: 0;
    }

    body {
      font-family: var(--font);
      font-size: 18px;
      font-weight: 300;
      line-height: 1.6;
      color: var(--fg);
      background: radial-gradient(1000px 400px at 50% -150px, rgba(23,114,208,0.12), rgba(255,255,255,0)) , var(--bg);
    }

    /* Links */
    a {
      color: var(--link);
      text-decoration: none;
    }
    a:visited {
      color: var(--link-visited);
    }
    a:focus, a:hover {
      color: var(--link-hover);
      text-decoration: none;
    }

    strong {
      font-weight: 400;
    }

    

    /* "Hi!" styling from the original template */
    .stretch-word {
      display: inline-block;
      font-weight: 700;
      font-size: 200%;
      vertical-align: bottom;
      float: left;
      padding-right: 6px;
      letter-spacing: 0.02em;
    }
/* Legacy custom tags used by the template */
    heading {
      display: block;
      font-size: 28px;
      font-weight: 400;
      letter-spacing: 0.2px;
      margin-bottom: 8px;
    }

    papertitle {
      font-size: 18px;
      font-weight: 500;
    }
    name {
      display: inline-block;
      font-weight: 400;
      font-size: 42px;
      letter-spacing: 0.2px;
    }

    /* Page wrapper: keep original centered layout but responsive */
    table.page {
      width: min(1000px, calc(100% - 28px));
      margin: 0 auto;
      border-collapse: separate;
      border-spacing: 0;
    }

    /* Subtle ‚Äúcard‚Äù look for major blocks without changing centering */
    table.page > tbody > tr > td > table {
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      box-shadow: var(--shadow);
      overflow: hidden;
      margin: 18px 0;
    }

    
    /* Section headers should not look like separate cards */
    table.section-header {
      background: transparent !important;
      border: 0 !important;
      box-shadow: none !important;
      margin: 14px 0 0 !important;
    }
    table.section-header td {
      padding-top: 0 !important;
      padding-bottom: 0 !important;
    }
    table.first-after-header {
      margin-top: 10px !important;
    }

/* Keep old tables readable on narrow screens */
    img {
      max-width: 100%;
      height: auto;
    }

    /* Section spacing: keep padding but make it consistent */
    td {
      color: var(--fg);
    }

    p {
      color: var(--muted);
      margin: 0.55em 0;
    }

    /* Logo row: keep uniform sizes */
    td.logo-cell {
      width: 25%;
      text-align: center;
      vertical-align: middle;
    }
    td.logo-cell img {
      max-height: 78px;
      width: auto;
      max-width: 100%;
      display: inline-block;
    }

    /* Profile image hover cursor (no animations) */
    .hover-pointer:hover {
      cursor: pointer;
    }

    /* Mobile/desktop helpers (kept for your current structure) */
    @media screen and (max-width: 1000px) {
      .desktop-only { display: none; }
      name { font-size: 38px; }
    }
    @media screen and (min-width: 1001px) {
      .mobile-only { display: none; }
    }

    /* Highlight */
    span.highlight {
      background-color: rgba(255, 255, 0, 0.20);
      padding: 0.05em 0.2em;
      border-radius: 6px;
    }

    /* ‚ÄúFancier but still plain‚Äù: nicer list spacing */
    ul {
      margin: 0.25em 0 0.25em 1.1em;
      padding: 0;
      color: var(--muted);
    }
    li {
      margin: 0.25em 0;
    }

        /* Theme toggle switch */
    .theme-toggle {
      position: fixed;
      top: 14px;
      right: 14px;
      z-index: 9999;
      display: inline-flex;
      align-items: center;
      justify-content: center;
    }

    .theme-toggle-input {
      width: 54px;
      height: 30px;
      appearance: none;
      -webkit-appearance: none;
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: 999px;
      box-shadow: var(--shadow);
      position: relative;
      cursor: pointer;
      outline: none;
    }

    .theme-toggle-input::before {
      content: "";
      position: absolute;
      top: 3px;
      left: 3px;
      width: 24px;
      height: 24px;
      border-radius: 999px;
      background: var(--fg);
      transform: translateX(0);
      transition: transform 120ms ease;
    }

    .theme-toggle-input::after {
      content: "üåô";
      position: absolute;
      top: 5px;
      right: 8px;
      font-size: 16px;
      line-height: 1;
      opacity: 0.9;
      pointer-events: none;
    }

    .theme-toggle-input:checked::before {
      transform: translateX(24px);
    }

    .theme-toggle-input:checked::after {
      content: "‚òÄÔ∏è";
      left: 8px;
      right: auto;
    }

    .theme-toggle-input:focus-visible {
      outline: 2px solid var(--link);
      outline-offset: 2px;
    }

    /* ===========================
       Dark-mode image adaptation
       - Applies to ALL images except those explicitly opted out.
       - Profile picture should stay unchanged (class="no-dark").
       - Favicon is unaffected by CSS anyway.
       =========================== */
    body.dark img:not(.no-dark) {
      /* Standard ‚Äúdark-mode for images‚Äù trick: invert + hue rotate + tune */
      filter: invert(0.92) hue-rotate(180deg) saturate(1.25) brightness(1.05) contrast(1.05);
    }

    /* Optional: keep paper figures crisp in dark mode */
    body.dark img:not(.no-dark) {
      image-rendering: auto;
    }
  
  </style>

  <script>
    // Ensure show-more toggles work even if script/functions.js is missing.
    function toggleblock(blockId) {
      var el = document.getElementById(blockId);
      if (!el) return;
      el.style.display = (el.style.display === "none" || el.style.display === "") ? "block" : "none";
    }

    // Profile image randomizer (robust vs. absolute URLs)
    function changeImage() {
      var img = document.getElementById('myImage');
      if (!img) return;

      var imagePaths = [
        'media/profile.jpg',
        'media/profile_object.jpeg',
        'media/profile_masked.png',
        'https://kochsebastian.com/media/profile.jpg',
        'https://kochsebastian.com/media/profile_object.jpeg',
        'https://kochsebastian.com/media/profile_masked.png'
      ];

      var currentPath = "";
      try {
        currentPath = new URL(img.src).pathname;
      } catch (e) {
        currentPath = img.src;
      }

      function sameImage(candidate) {
        try {
          return currentPath.endsWith(new URL(candidate, window.location.href).pathname);
        } catch (e) {
          return currentPath.endsWith(candidate);
        }
      }

      var filtered = imagePaths.filter(function(p) { return !sameImage(p); });
      if (filtered.length === 0) return;

      var nextSrc = filtered[Math.floor(Math.random() * filtered.length)];
      img.src = nextSrc;
    }

    // Dark mode toggle: light default + localStorage override.
    (function() {
      var storageKey = "theme";
      var inputId = "themeToggle";

      function setTheme(mode) {
        var isDark = (mode === "dark");
        document.body.classList.toggle("dark", isDark);

        var input = document.getElementById(inputId);
        if (input) input.checked = isDark;
      }

      function initTheme() {
        var saved = null;
        try { saved = localStorage.getItem(storageKey); } catch (e) {}
        // Default is LIGHT (no system-preference auto-switching)
        var mode = (saved === "dark" || saved === "light") ? saved : "light";
        setTheme(mode);
      }

      function onToggle(e) {
        var isDark = !!(e && e.target && e.target.checked);
        var mode = isDark ? "dark" : "light";
        try { localStorage.setItem(storageKey, mode); } catch (e) {}
        setTheme(mode);
      }

      window.addEventListener("DOMContentLoaded", function() {
        initTheme();
        var input = document.getElementById(inputId);
        if (input) input.addEventListener("change", onToggle);
      });
    })();
  </script>

  <!-- Keep your existing helper script (optional) -->
  <script src="script/functions.js"></script>
</head>

<body>
  <div class="theme-toggle" aria-label="Theme">
    <input id="themeToggle" class="theme-toggle-input" type="checkbox" role="switch" aria-label="Toggle dark mode">
  </div>

  <table id="page" class="page" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" class="desktop-only">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Sebastian Koch</name>
        </p>
        <p>
          <span class="stretch-word">Hi!</span> 
          I am a PhD student at <a href="https://www.uni-ulm.de/en/">University Ulm</a> advised by <a href="https://viscom.uni-ulm.de/members/timo-ropinski/">Timo Ropinski</a> and a Google Student Researcher working closly with <a href="https://scholar.google.com/citations?user=dfjN3YAAAAAJ&hl=en"> Johanna Wald</a> and <a href="https://federicotombari.github.io/">Federico Tombari</a>. Previously, I have been an industrial PhD Student at the <a href="https://www.bosch-ai.com/">Bosch Center for AI</a>.
          </p>
          <p  align="justify">
          My main research interest lies at the intersection of 3D scene understanding and embodied AI, focusing on investigating novel scene representations of real-world environments that include object semantics as well as information about object interactions and their relationships. My work aims to enable robots to navigate and solve tasks more effectively by leveraging a detailed understanding of their environment.
          </p>
          <p  align="justify">
          I completed my master's degree in computer science at the <a href="https://uni-tuebingen.de/en">University of T√ºbingen</a>. In my master's thesis, I investigated multi-view and symmetry-aware 6D pose estimation under the guidance of <a href="https://www.cvlibs.net/">Andreas Geiger</a> and <a href="https://alr.anthropomatik.kit.edu/21_65.php">Gerhard Neumann</a>, in collaboration with <a href="https://www.bosch-ai.com/">BCAI</a>.
          Additionally, I worked as a research assistant in the Cognitive Systems lab, focusing on hardware-efficient remote sensing methods with <a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/kognitive-systeme/the-chair/staff/prof-dr-andreas-zell/">Andreas Zell</a>.
          Before that, I pursued my bachelor's degree in computer science at <a href="https://www.dhbw-stuttgart.de/en">DHBW Stuttgart</a>. I also gained practical experience through multiple internships at <a href="https://www.bosch.de/en/">Bosch</a>, with focus on perception in robotics and autonomous driving.
          </p>
        <p align=center>
          <a href="mailto:kochsebastian98@gmail.com">Email</a> &nbsp|&nbsp
          <a href="files/cv_2025_3page.pdf">CV</a> &nbsp|&nbsp
          <a href="https://github.com/kochsebastian">GitHub</a> &nbsp|&nbsp
          <a href="https://scholar.google.com/citations?user=hX7EOUkAAAAJ&hl=en">Google Scholar</a> &nbsp|&nbsp
          <a href="https://www.linkedin.com/in/sebastian-koch-9ba94316a/"> LinkedIn</a>
          &nbsp|&nbsp
          <a href="https://twitter.com/sebastiankoch98">Twitter</a>
        </p>
        </td>
        <td width="33%">
            <img id="myImage" class="hover-pointer no-dark" src="media/profile.jpg" width="250" onclick="changeImage()"> 
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" class="mobile-only">
        <tr>
          <td width="100%" valign="middle">
          <p align="center">
            <name>Sebastian Koch</name>
          </p>
          <p align="center">
            <img id="myImage" class="no-dark" src="media/profile.jpg" width="450" onclick="changeImage()"> 
          </p>
          
          <p>
            <span class="stretch-word">Hi!</span> 
            I‚Äôm a final-year PhD student at the <a href="https://www.uni-ulm.de/en/">University of Ulm</a>, advised by <a href="https://viscom.uni-ulm.de/members/timo-ropinski/">Timo Ropinski</a>. During my PhD, I closely collaborate with <a href="https://scholar.google.com/citations?user=dfjN3YAAAAAJ&hl=en">Johanna Wald</a> and <a href="https://federicotombari.github.io/">Federico Tombari</a> at Google. For the first three years of my PhD, I was funded by and collaborated with the <a href="https://www.bosch-ai.com/">Bosch Center for AI</a>.            </p>
            <p  align="justify">
            My main research interest lies at the intersection of 3D scene understanding and embodied AI, focusing on investigating novel scene representations of real-world environments that include object semantics as well as information about object interactions and their relationships. My work aims to enable robots to navigate and solve tasks more effectively by leveraging a detailed understanding of their environment.
            </p>
            <p  align="justify">
            I completed my master's degree in computer science at the <a href="https://uni-tuebingen.de/en">University of T√ºbingen</a>. In my master's thesis, I investigated multi-view and symmetry-aware 6D pose estimation under the guidance of <a href="https://www.cvlibs.net/">Andreas Geiger</a> and <a href="https://alr.anthropomatik.kit.edu/21_65.php">Gerhard Neumann</a>, in collaboration with <a href="https://www.bosch-ai.com/">BCAI</a>.
            Additionally, I worked as a research assistant in the Cognitive Systems lab, focusing on hardware-efficient remote sensing methods with <a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/kognitive-systeme/the-chair/staff/prof-dr-andreas-zell/">Andreas Zell</a>.
            Before that, I pursued my bachelor's degree in computer science at <a href="https://www.dhbw-stuttgart.de/en">DHBW Stuttgart</a>. I also gained practical experience through multiple internships at <a href="https://www.bosch.de/en/">Bosch</a>, with focus on perception in robotics and autonomous driving.
            </p>
          <p align=center>
            <a href="mailto:kochsebastian98@gmail.com">Email</a> &nbsp|&nbsp
            <a href="files/cv_2025_3page.pdf">CV</a> &nbsp|&nbsp
            <a href="https://github.com/kochsebastian">GitHub</a> &nbsp|&nbsp
            <a href="https://scholar.google.com/citations?user=hX7EOUkAAAAJ&hl=en">Google Scholar</a> &nbsp|&nbsp
            <a href="https://www.linkedin.com/in/sebastian-koch-9ba94316a/"> LinkedIn</a>
            &nbsp|&nbsp
            <a href="https://twitter.com/sebastiankoch98">Twitter</a>
          </p>
          </td>
        </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td class="logo-cell">
              <a href="https://www.uni-ulm.de/en/">
                <img src="media/uni_ulm_logo.png" alt="Uni Ulm logo">
              </a>
            </td>
            <td class="logo-cell">
              <a href="https://research.google">
                <img src="media/Google_2015_logo.png" alt="Google logo">
              </a>
            </td>
            <td class="logo-cell">
              <a href="https://www.bosch-ai.com/">
                <img src="media/bosch_logo.png" alt="Bosch logo">
              </a>
            </td>
            <td class="logo-cell">
              <a href="https://uni-tuebingen.de/en">
                <img src="media/uni_tuebingen_logo.png" alt="Uni T√ºbingen logo">
              </a>
            </td>
          </tr>
        </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
          <heading>News</heading>
            <ul>
              <li><strong>05/2025</strong> I was named an <a href="https://cvpr.thecvf.com/Conferences/2025/ProgramCommittee#all-outstanding-reviewer">Oustanding Reviewer</a> at <strong>CVPR 2025</strong>. Super proud about this!</li>
              <li><strong>05/2025</strong> I left Bosch Center for AI and joined Google Munich as a Student Researcher for the next 6 months!</li>
              <li><strong>02/2025</strong> My paper <a href="https://relationfield.github.io"><strong>RelationField</strong></a> got accepted at <strong>CVPR 2025</strong>! </li>
              <li><strong>02/2025</strong> I gave a talk on Language-driven 3D Scene Graph prediction at the Huawei Munich Research Center <a href="media/Language-driven Scene Understanding-huawai_Feb2025.pdf"> (Slides)</a>.</li>
              <li><strong>04/2024</strong> I was accepted at the prestigious International Computer Vision Summer School <strong>ICVSS 2024</strong>.</li>
              <li><strong>02/2024</strong> My paper <a href="https://kochsebastian.com/open3dsg"><strong>Open3DSG</strong></a> got accepted at <strong>CVPR 2024</strong>! I will also present it at the OpenSUN & SG2RL workshop.</li>
              <li><strong>10/2023</strong> My paper <a href="https://kochsebastian.com/sgrec3d"><strong>SGRec3D</strong></a> got accepted at <strong>WACV 2024</strong>! </li>
              <li><strong>10/2023</strong> My paper <a href="https://kochsebastian.com/lang3dsg"><strong>Lang3DSG</strong></a> got accepted at <strong>3DV 2024</strong>! </li>
              <a href="javascript:toggleblock(&#39;old_news&#39;)">---- show more ----</a>
              <div id="old_news" style="display: none;">
              <li><strong>08/2023</strong> I got an workshop paper accepted at the <strong>SG2RL workshop</strong> held at <strong>ICCV 2023</strong> in Paris!</li>
              <li><strong>07/2023</strong> Our follow-up paper to my master's thesis <a href="https://arxiv.org/pdf/2307.00306.pdf"><strong>SyMFM6D</strong></a> has been accepted at <strong>RA-L</strong></li>
               
                <li><strong>04/2022</strong> Start of my PhD journey at <a href="https://www.uni-ulm.de/en/">Ulm University</a> & <a href="https://www.bosch-ai.com/">Bosch Research/BCAI</a>. </li>
                <li><strong>03/2022</strong> I successfully defended my master's thesis on multi-view 6D pose estimation!</li>
                <!-- <li><strong>03/2022</strong> I successfully defended my master's thesis on multi-view 6D pose estimation!</li> -->
            </div></div>
            
            </ul>
        </td>
      </tr>
      </table>
      <table class="section-header" width="100%" align="center" border="0" cellspacing="0" cellpadding="12" >
        <tr>
          <td width="100%" valign="middle">
            <heading>Research</heading>
          </td>
        </tr>
      </table>
      <table class="first-after-header" width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
        <tr>
          <td width="25%">
            <div class="">
            <img src='media/unite/unite_teaser.png' width="100%"></div>
          </td>
          <td valign="middle" width="100%">
              <a href="https://unite-page.github.io/">
                <papertitle>
                  Unified Semantic Transformer for 3D Scene Understanding
                </papertitle>
              </a>
          <br>
              <strong>Sebastian Koch</strong>, 
              <a href="https://scholar.google.com/citations?user=dfjN3YAAAAAJ&hl=en&oi=ao"> Johanna Wald</a>,
              <a href="https://muskie82.github.io/">Hidenobu Matsuki</a>,
              <a href="https://phermosilla.github.io/">Pedro Hermosilla</a>, 
              <br>
              <a href="https://viscom.uni-ulm.de/members/timo-ropinski/">Timo Ropinski</a>,
              <a href="https://federicotombari.github.io/">Federico Tombari</a>
          <br>
          <!-- <em> Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>) </em>, 2025 -->
            <!-- <br> -->
            <a href="https://arxiv.org/abs/2512.14364">paper</a> |
             <a href="https://unite-page.github.io/"> project page</a> |
             <a href="bib/koch2025unite.bib">bibtex</a>
            <p></p>
            A single feed-forward model that unifies multiple 3D semantic tasks from RGB input.
            <p></p>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
        <tr>
          <td width="25%">
            <div class="">
            <img src='media/openhype.png' width="100%"></div>
          </td>
          <td valign="middle" width="100%">
              <a href="https://lisaweijler.github.io/openhype-projectpage/">
                <papertitle>
                  OpenHype: Hyperbolic Embeddings for Hierarchical Open-Vocabulary Radiance Fields
                </papertitle>
              </a>
          <br>
          <a href="https://lisaweijler.github.io/">Lisa Weijler</a>,
              <strong>Sebastian Koch</strong>, 
              <a href="https://fabiopoiesi.github.io/">Fabio Poiesi</a>,
              <a href="https://viscom.uni-ulm.de/members/timo-ropinski/">Timo Ropinski</a>,
              <a href="https://phermosilla.github.io/">Pedro Hermosilla</a>
          <br>
          <em> Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>) </em>, 2025
            <br>
            <a href="https://lisaweijler.github.io/openhype-projectpage/static/images/OpenHype.pdf">paper</a> |
             <a href="https://lisaweijler.github.io/openhype-projectpage/"> project page</a> |
             <a href="bib/weijler2025openhype.bib">bibtex</a>
            <p></p>
            Radiance fields with hyperbolic open-vocabulary features enabling reasoning over object hierarchies.
            <p></p>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
        <tr>
          <td width="25%">
            <div class="">
            <img src='media/relationfield/relationfield_teaser.png' width="100%"></div>
          </td>
          <td valign="middle" width="100%">
              <a href="https://relationfield.github.io">
                <papertitle>
                  RelationField: Relate Anything in Radiance Fields
                </papertitle>
              </a>
          <br>
              <strong>Sebastian Koch</strong>, 
              <a href="https://scholar.google.com/citations?user=dfjN3YAAAAAJ&hl=en&oi=ao"> Johanna Wald</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=k4m1c6EAAAAJ">Mirco Colosi</a>,
              <a href="https://scholar.google.com/citations?user=U3KSTwkAAAAJ&hl=en"> Narunas Vaskevicius</a>,
              <a href="https://phermosilla.github.io/">Pedro Hermosilla</a>, 
              <a href="https://federicotombari.github.io/">Federico Tombari</a>, 
              <a href="https://viscom.uni-ulm.de/members/timo-ropinski/">Timo Ropinski</a>
          <br>
          <em> IEEE / CVF Computer Vision and Pattern Recognition Conference (<strong>CVPR</strong>) </em>, 2025
            <br>
            <a href="media/relationfield/relationfield_arxiv.pdf">paper</a> |
             <a href="https://relationfield.github.io"> project page</a> |
             <a href="https://github.com/boschresearch/RelationField">code</a> |
             <a href="bib/koch2025relationfield.bib">bibtex</a>
            <p></p>
            Open-Vocabulary 3D Relationships in Radiance Fields, learned solely from 2D image supervision.
            <p></p>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
        <tr>
          <td width="25%">
            <div class="">
            <img src='media/delta/sg_allensville.drawio.png' width="100%"></div>
          </td>
          <td valign="middle" width="100%">
              <a href="https://delta-llm.github.io/">
                <papertitle>
                  DELTA: Decomposed Efficient Long-Term Robot Task Planning using Large Language Models
                </papertitle>
              </a>
          <br>
              <a href="https://scholar.google.com/citations?user=dAfwuBQAAAAJ&hl=en"> Yuchen Liu</a>,
              <a href="https://palmieri.github.io/">Luigi Palmieri</a>,    
              <strong>Sebastian Koch</strong>, 
              <a href="https://scholar.google.com/citations?user=RN7G80gAAAAJ&hl=en"> Ilche Georgievski</a>, 
              <a href="https://scholar.google.com/citations?user=XvRUyU4AAAAJ&hl=en">Marco Aiello</a>
          <br>
          <em> IEEE International Conference on Robotics & Automation (<strong>ICRA</strong>) </em>, 2025
            <br>
            <a href="https://arxiv.org/pdf/2404.03275">paper</a> |
             <a href="https://delta-llm.github.io/"> project page</a> |
            <a href="media/delta/liu2025delta.bib">bibtex</a>
            <p></p>
            Long-term robot task planning with 3D Scene Graphs and LLMs.
            <p></p>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
        <tr>
          <td width="25%">
            <div class="">
            <img src='media/open3dsg/teaser.png' width="100%"></div>
          </td>
          <td valign="middle" width="100%">
              <a href="https://kochsebastian.com/open3dsg">
                <papertitle>
                  Open3DSG: Open-Vocabulary 3D Scene Graphs from Point Clouds <br>with Queryable Objects and Open-Set Relationships
                </papertitle>
              </a>
          <br>
              <strong>Sebastian Koch</strong>, 
              <a href="https://scholar.google.com/citations?user=U3KSTwkAAAAJ&hl=en"> Narunas Vaskevicius</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=k4m1c6EAAAAJ&view_op=list_works&sortby=pubdate">Mirco Colosi</a>,
              <a href="https://phermosilla.github.io/">Pedro Hermosilla</a>, 
              <a href="https://viscom.uni-ulm.de/members/timo-ropinski/">Timo Ropinski</a>
          <br>
          <em> IEEE / CVF Computer Vision and Pattern Recognition Conference (<strong>CVPR</strong>) </em>, 2024
            <br>
            <a href="media/open3dsg/open3dsg_camera.pdf">paper</a> |
             <a href="https://kochsebastian.com/open3dsg"> project page</a> |
             <a href="media/open3dsg/open3dsg_poster.pdf">poster</a> |
             <a href="https://github.com/boschresearch/Open3DSG">code</a> |
             <a href="https://youtu.be/1DL8R_ZfpLw?si=XlajcJEsFngUXDgI">video</a> |
            <a href="bib/koch2024open3dsg.bib">bibtex</a>
            <p></p>
            The first open-vocabulary 3D scene graph method with open-world relationships.
            <p></p>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
        <tr>
          <td width="25%">
            <div class="">
            <img halign="center" src='media/lang3dsg/teaser.png' width="100%">
          </div>
          </td>
          <td valign="middle" width="100%">
              <a href="https://kochsebastian.com/lang3dsg">
                <papertitle>
                  Lang3DSG: Language-based contrastive pre-training for 3D Scene Graph prediction
                </papertitle>
              </a>
          <br>
              <strong>Sebastian Koch</strong>, 
              <a href="https://phermosilla.github.io/">Pedro Hermosilla</a>, 
              <a href="https://scholar.google.com/citations?user=U3KSTwkAAAAJ&hl=en"> Narunas Vaskevicius</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=k4m1c6EAAAAJ&view_op=list_works&sortby=pubdate">Mirco Colosi</a>,
              <a href="https://viscom.uni-ulm.de/members/timo-ropinski/">Timo Ropinski</a>
          <br>
          <em>International Conference on 3D Vision (<strong>3DV</strong>)</em>, 2024
            <br>
            <a href="files/Koch2024Lang3DSG.pdf">paper</a> |
            <a href="https://kochsebastian.com/lang3dsg">project page</a> |
            <a href="media/lang3dsg/3dv2024-1163.pdf">poster</a> |
            <!-- <a href="link">video</a> | -->
            <a href="bib/koch2024lang3dsg.bib">bibtex</a>
            <p></p>
            Language and 3D scene graph alignment using contrastive pre-training.
            <p></p>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
        <tr>
          <td width="25%">
            <div class="">
            <img src='media/auto3dsg_preview.png' width="100%"></div>
          </td>
          <td valign="middle" width="100%">
              <a href="https://kochsebastian.com/sgrec3d">
                <papertitle>
                  SGRec3D: Self-Supervised 3D Scene Graph Learning via Object-Level Scene Reconstruction
                </papertitle>
              </a>
          <br>
              <strong>Sebastian Koch</strong>, 
              <a href="https://phermosilla.github.io/">Pedro Hermosilla</a>, 
              <a href="https://scholar.google.com/citations?user=U3KSTwkAAAAJ&hl=en"> Narunas Vaskevicius</a>,
              <a href="https://scholar.google.com/citations?hl=en&user=k4m1c6EAAAAJ&view_op=list_works&sortby=pubdate">Mirco Colosi</a>,
              <a href="https://viscom.uni-ulm.de/members/timo-ropinski/">Timo Ropinski</a>
          <br>
          <em>IEEE Winter Conference on Applications of Computer Vision (<strong>WACV</strong>)</em>, 2024
            <br>
            <a href="files/Koch_SGRec3D_WACV2024.pdf">paper</a> |
            <a href="https://kochsebastian.com/sgrec3d">project page</a> |
            <a href="media/sgrec3d/wacv2024-1163.pdf">poster</a> |
            <a href="https://youtu.be/YB4n_vi0RoE">video</a> |
            <a href="bib/koch2024sgrec3d.bib">bibtex</a>
            <p></p>
            A label-efficient method to predict 3D semantic scene graphs for indoor environments.
            <p></p>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
        <tr>
          <td width="25%">
            <div class="" align="center">
            <img hallign="middle" src='media/SyMFM6D_eyecatcher.jpg' width="95%" ></div>
          </td>
          <td valign="middle" width="100%">
              <a href="https://arxiv.org/pdf/2307.00306.pdf">
                <papertitle>
                  SyMFM6D: Symmetry-aware Multi-directional Fusion for Multi-View 6D Object Pose Estimation
                </papertitle>
              </a>
          <br>
              <a href="https://alr.anthropomatik.kit.edu/21_114.php">Fabian Duffhau√ü</a>, 
              <strong>Sebastian Koch</strong>, 
              <a href="https://www.bosch-ai.com/research/researcher-pages/t_overviewpage_129.html">Hanna Ziesche</a>, 
              <a href="https://scholar.google.com/citations?user=xk1gsM8AAAAJ&hl=en">Ngo Anh Vien</a>,
              <a href="https://alr.anthropomatik.kit.edu/21_65.php">Gerhard Neumann</a>
          <br>
          <em>IEEE Robotics and Automation Letter (<strong>RA-L</strong>)</em>, 2023 & International Conference on Robotics and Automation (<strong>ICRA</strong>) 2024
            <br>
            <a href="https://arxiv.org/abs/2307.00306">paper</a> |
            <!-- <a href="link">project page</a> | -->
            <!-- <a href="link">video</a> | -->
            <a href="https://github.com/boschresearch/SyMFM6D">code</a> |
            <a href="bib/duffhauss2023symfm6d.bib">bibtex</a>
            <p></p>
            A 6D pose estimation approach utilizing multiple viewpoints and considering object symmetries.
            <p></p>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
        <tr>
          <td width="25%">
            <div class="" align="center">
            <img halign="middle" src='media/ycb_pose.png' width="80%"></div>
          </td>
          
          <td valign="middle" width="100%">
              <a href="https://arxiv.org/pdf/2307.00306.pdf">
                <papertitle>
                  Multi-View RGB-D Fusion for 6D Pose Estimation
                </papertitle>
              </a>
          <br>
              <strong>Sebastian Koch</strong>, 
          <br>
          <em>M.Sc. Thesis, University of T√ºbingen</em>, 2022
            <br>
            <a href="media/MasterThesis.pdf">thesis</a> |
            <!-- <a href="link">project page</a> | -->
            <!-- <a href="link">video</a> | -->
            <a href="media/FinalMasterThesisPresentation.pdf">slides</a> |
            <a href="bib/msc.bib">bibtex</a>
            <p></p>
            <p></p>
          </td>
        </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" >
        <tr>
          <td width="25%">
            <div class="" align="center">
            <img src='media/preview_drone.png' width="80%"></div>
          </td>
          
          <td valign="middle" width="100%">
              <a href="https://www.mdpi.com/2072-4292/14/21/5508">
                <papertitle>
                  Comprehensive Analysis of the Object Detection Pipeline on UAVs
                </papertitle>
              </a>
          <br>
          <a href="https://scholar.google.com/citations?user=4XOjpZ8AAAAJ&hl=en">Leon Amadeus Varga</a>, <strong>Sebastian Koch</strong>, <a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/kognitive-systeme/the-chair/staff/prof-dr-andreas-zell/">Andreas Zell</a>, 
          <br>
          <em>Remote Sensing</em>, 2022
            <br>
            <a href="https://www.mdpi.com/2072-4292/14/21/5508">paper</a> |
            <a href="https://github.com/cogsys-tuebingen/cp_eval">code</a> |
            <a href="bib/varga2022comprehensive.bib">bibtex</a>
            <p></p>
            <p></p>
          </td>
        </tr>
      </table>
      <table>
        <a href="javascript:toggleblock(&#39;projects&#39;)">---- More ----</a>
              <div id="projects" style="display: none;">
                <!-- <strong>03/2022</strong> I successfully defended my master's thesis on multi-view 6D pose estimation! -->
            </div>
      </table>
      
    </td>
    </tr>
    
  </table>
  

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td>
      <br>
      <p align="center">
        <font size="1">
        template adapted from <a href="https://jonbarron.info/"><font size="1">this awesome website</font></a>
      </font>
      </p>
      </td>
    </tr>
  </table>

</body>
</html>
